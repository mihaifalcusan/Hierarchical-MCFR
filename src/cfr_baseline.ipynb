{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f222c7",
   "metadata": {},
   "source": [
    "This tutorial is licensed by [Bernard Koch](http://www.github.com/kochbj) under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/). The following file is adapted based on the code provided by B.Koch and the adapted tutorial by Roberto Faleh (https://github.com/roberfal), modifications and adaptations were done by me (Mihai Falcusan)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba42440",
   "metadata": {},
   "source": [
    "# CFRNet Baseline\n",
    "\n",
    "This is a cleaned version of the given binary cfrnet implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d6e1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import datetime #we'll use dates to label our logs\n",
    "print(tf.__version__)\n",
    "import os\n",
    "\n",
    "import urllib #Adapted for windows. Please use the corresponding eg  -GET if you are on different OS.\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f3cbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory relative to your current location (src)\n",
    "output_dir = \"../dat\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Use os.path.join() to create the full file paths\n",
    "train_file_path = os.path.join(output_dir, \"100.train.npz\")\n",
    "test_file_path = os.path.join(output_dir, \"100.test.npz\")\n",
    "\n",
    "# Update urllib.request.urlretrieve to save to the new paths\n",
    "train=urllib.request.urlretrieve(\"http://www.fredjo.com/files/ihdp_npci_1-100.train.npz\", train_file_path)[0]\n",
    "test=urllib.request.urlretrieve(\"http://www.fredjo.com/files/ihdp_npci_1-100.test.npz\", test_file_path)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbca94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate and rescale data\n",
    "def load_IHDP_data(training_data,testing_data,i=7):\n",
    "    with open(training_data,'rb') as trf, open(testing_data,'rb') as tef:\n",
    "        train_data=np.load(trf); test_data=np.load(tef)\n",
    "        y=np.concatenate( (train_data['yf'][:,i], test_data['yf'][:,i])).astype('float32') #most GPUs only compute 32-bit floats\n",
    "        t=np.concatenate( (train_data['t'][:,i], test_data['t'][:,i])).astype('float32')\n",
    "        x=np.concatenate( (train_data['x'][:,:,i], test_data['x'][:,:,i]),axis=0).astype('float32')\n",
    "        mu_0=np.concatenate((train_data['mu0'][:,i], test_data['mu0'][:,i])).astype('float32')\n",
    "        mu_1=np.concatenate((train_data['mu1'][:,i], test_data['mu1'][:,i])).astype('float32')\n",
    "\n",
    "        data={'x':x,'t':t,'y':y,'t':t,'mu_0':mu_0,'mu_1':mu_1}\n",
    "        data['t']=data['t'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension \n",
    "        data['y']=data['y'].reshape(-1,1)\n",
    "        \n",
    "        #rescaling y between 0 and 1 often makes training of DL regressors easier\n",
    "        data['y_scaler'] = StandardScaler().fit(data['y'])\n",
    "        data['ys'] = data['y_scaler'].transform(data['y'])\n",
    "\n",
    "    return data\n",
    "\n",
    "data=load_IHDP_data(training_data=train,testing_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb425e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare loss\n",
    "\n",
    "def pdist2sq(x,y):\n",
    "    x2 = tf.reduce_sum(x ** 2, axis=-1, keepdims=True)\n",
    "    y2 = tf.reduce_sum(y ** 2, axis=-1, keepdims=True)\n",
    "    dist = x2 + tf.transpose(y2, (1, 0)) - 2. * x @ tf.transpose(y, (1, 0))\n",
    "    return dist\n",
    "\n",
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "class CFRNet_Loss(Loss):\n",
    "  #initialize instance attributes\n",
    "  def __init__(self, alpha=1.,sigma=1.):\n",
    "      super().__init__()\n",
    "      self.alpha = alpha # balances regression loss and MMD IPM\n",
    "      self.rbf_sigma=sigma #for gaussian kernel\n",
    "      self.name='cfrnet_loss'\n",
    "      \n",
    "  def split_pred(self,concat_pred):\n",
    "      #generic helper to make sure we dont make mistakes\n",
    "      preds={}\n",
    "      preds['y0_pred'] = concat_pred[:, 0]\n",
    "      preds['y1_pred'] = concat_pred[:, 1]\n",
    "      preds['phi'] = concat_pred[:, 2:]\n",
    "      return preds\n",
    "\n",
    "  def rbf_kernel(self, x, y):\n",
    "    return tf.exp(-pdist2sq(x,y)/tf.square(self.rbf_sigma))\n",
    "\n",
    "  def calc_mmdsq(self, Phi, t):\n",
    "    Phic, Phit =tf.dynamic_partition(Phi,tf.cast(tf.squeeze(t),tf.int32),2)\n",
    "\n",
    "    Kcc = self.rbf_kernel(Phic,Phic)\n",
    "    Kct = self.rbf_kernel(Phic,Phit)\n",
    "    Ktt = self.rbf_kernel(Phit,Phit)\n",
    "\n",
    "    m = tf.cast(tf.shape(Phic)[0],Phi.dtype)\n",
    "    n = tf.cast(tf.shape(Phit)[0],Phi.dtype)\n",
    "\n",
    "    mmd = 1.0/(m*(m-1.0))*(tf.reduce_sum(Kcc))\n",
    "    mmd = mmd + 1.0/(n*(n-1.0))*(tf.reduce_sum(Ktt))\n",
    "    mmd = mmd - 2.0/(m*n)*tf.reduce_sum(Kct)\n",
    "    return mmd * tf.ones_like(t)\n",
    "\n",
    "  def mmdsq_loss(self, concat_true,concat_pred):\n",
    "    t_true = concat_true[:, 1]\n",
    "    p=self.split_pred(concat_pred)\n",
    "    mmdsq_loss = tf.reduce_mean(self.calc_mmdsq(p['phi'],t_true))\n",
    "    return mmdsq_loss\n",
    "\n",
    "  def regression_loss(self,concat_true,concat_pred):\n",
    "      y_true = concat_true[:, 0]\n",
    "      t_true = concat_true[:, 1]\n",
    "      p = self.split_pred(concat_pred)\n",
    "      loss0 = tf.reduce_mean((1. - t_true) * tf.square(y_true - p['y0_pred']))\n",
    "      loss1 = tf.reduce_mean(t_true * tf.square(y_true - p['y1_pred']))\n",
    "      return loss0+loss1\n",
    "\n",
    "  def cfr_loss(self, concat_true, concat_pred):\n",
    "    lossR = self.regression_loss(concat_true, concat_pred)  # loss di regressione\n",
    "    lossIPM = self.mmdsq_loss(concat_true, concat_pred)     # penalità MMD\n",
    "    return lossR + self.alpha * lossIPM\n",
    "\n",
    "      \n",
    "\n",
    "  #compute loss\n",
    "  def call(self, concat_true, concat_pred):        \n",
    "      return self.cfr_loss(concat_true,concat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58df7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class Base_Metrics(Callback):\n",
    "    def __init__(self,data, verbose=0):   \n",
    "        super(Base_Metrics, self).__init__()\n",
    "        self.data=data #feed the callback the full dataset\n",
    "        self.verbose=verbose\n",
    "\n",
    "        #needed for PEHEnn; Called in self.find_ynn\n",
    "        self.data['o_idx']=tf.range(self.data['t'].shape[0])\n",
    "        self.data['c_idx']=self.data['o_idx'][self.data['t'].squeeze()==0] #These are the indices of the control units\n",
    "        self.data['t_idx']=self.data['o_idx'][self.data['t'].squeeze()==1] #These are the indices of the treated units\n",
    "    \n",
    "    def split_pred(self,concat_pred):\n",
    "        preds={}\n",
    "        preds['y0_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 0].reshape(-1, 1))\n",
    "        preds['y1_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 1].reshape(-1, 1))\n",
    "        preds['phi'] = concat_pred[:, 2:]\n",
    "        return preds\n",
    "\n",
    "    def find_ynn(self, Phi):\n",
    "        #helper for PEHEnn\n",
    "        PhiC, PhiT =tf.dynamic_partition(Phi,tf.cast(tf.squeeze(self.data['t']),tf.int32),2) #separate control and treated reps\n",
    "        dists=tf.sqrt(pdist2sq(PhiC,PhiT)) #calculate squared distance then sqrt to get euclidean\n",
    "        yT_nn_idx=tf.gather(self.data['c_idx'],tf.argmin(dists,axis=0),1) #get c_idxs of smallest distances for treated units\n",
    "        yC_nn_idx=tf.gather(self.data['t_idx'],tf.argmin(dists,axis=1),1) #get t_idxs of smallest distances for control units\n",
    "        yT_nn=tf.gather(self.data['y'],yT_nn_idx,1) #now use these to retrieve y values\n",
    "        yC_nn=tf.gather(self.data['y'],yC_nn_idx,1)\n",
    "        y_nn=tf.dynamic_stitch([self.data['t_idx'],self.data['c_idx']],[yT_nn,yC_nn]) #stitch em back up!\n",
    "        return y_nn\n",
    "\n",
    "    def PEHEnn(self,concat_pred):\n",
    "        p = self.split_pred(concat_pred)\n",
    "        y_nn = self.find_ynn(p['phi']) \n",
    "        cate_nn_err=tf.reduce_mean( tf.square( (1-2*self.data['t']) * (y_nn-self.data['y']) - (p['y1_pred']-p['y0_pred']) ) )\n",
    "        return cate_nn_err\n",
    "\n",
    "    def ATE(self,concat_pred):\n",
    "        p = self.split_pred(concat_pred)\n",
    "        return p['y1_pred']-p['y0_pred']\n",
    "\n",
    "    def PEHE(self,concat_pred):\n",
    "        #simulation only\n",
    "        p = self.split_pred(concat_pred)\n",
    "        cate_err=tf.reduce_mean( tf.square( ( (self.data['mu_1']-self.data['mu_0']) - (p['y1_pred']-p['y0_pred']) ) ) )\n",
    "        return cate_err \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        concat_pred=self.model.predict(self.data['x'])\n",
    "        #Calculate Empirical Metrics        \n",
    "        ate_pred=tf.reduce_mean(self.ATE(concat_pred)); tf.summary.scalar('ate', data=ate_pred, step=epoch)\n",
    "        pehe_nn=self.PEHEnn(concat_pred); tf.summary.scalar('cate_nn_err', data=tf.sqrt(pehe_nn), step=epoch)\n",
    "        \n",
    "        #Simulation Metrics\n",
    "        ate_true=tf.reduce_mean(self.data['mu_1']-self.data['mu_0'])\n",
    "        ate_err=tf.abs(ate_true-ate_pred); tf.summary.scalar('ate_err', data=ate_err, step=epoch)\n",
    "        pehe =self.PEHE(concat_pred); tf.summary.scalar('cate_err', data=tf.sqrt(pehe), step=epoch)\n",
    "        out_str=f' — ate_err: {ate_err:.4f}  — cate_err: {tf.sqrt(pehe):.4f} — cate_nn_err: {tf.sqrt(pehe_nn):.4f} — true_ate: {ate_true:.4f}'\n",
    "        \n",
    "        if self.verbose > 0: print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eebbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def make_tarnet(input_dim, reg_l2):\n",
    "    '''\n",
    "    The first argument is the column dimension of our data.\n",
    "    It needs to be specified because the functional API creates a static computational graph\n",
    "    The second argument is the strength of regularization we'll apply to the output layers\n",
    "    '''\n",
    "    x = Input(shape=(input_dim,), name='input')\n",
    "\n",
    "    # REPRESENTATION\n",
    "    #in TF2/Keras it is idiomatic to instantiate a layer and pass its inputs on the same line unless the layer will be reused\n",
    "    #Note that we apply no regularization to the representation layers\n",
    "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(x)\n",
    "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_2')(phi)\n",
    "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_3')(phi)\n",
    "\n",
    "    # HYPOTHESIS\n",
    "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n",
    "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n",
    "\n",
    "    # second layer\n",
    "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_2')(y0_hidden)\n",
    "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_2')(y1_hidden)\n",
    "\n",
    "    # third\n",
    "    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n",
    "    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n",
    "\n",
    "    #a convenience \"layer\" that concatenates arrays as columns in a matrix\n",
    "    concat_pred = Concatenate(1)([y0_predictions, y1_predictions])\n",
    "    #the declarations above have specified the computational graph of our network, now we instantiate it\n",
    "    model = Model(inputs=x, outputs=concat_pred)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0df2fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:35:15.724240: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  cfrnet_loss: 1.0947 - loss: 5.7891 - mmdsq_loss: 0.0741 - regression_loss: \n",
      " — ate_err: 2.9013  — cate_err: 3.3015 — cate_nn_err: 3.8127 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - cfrnet_loss: 1.0341 - loss: 5.7251 - mmdsq_loss: 0.0722 - regression_loss: 0.9619 - val_cfrnet_loss: 1.2537 - val_loss: 5.8244 - val_mmdsq_loss: 0.2071 - val_regression_loss: 1.0466 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.8370 - loss: 5.5005 - mmdsq_loss: 0.0741 - regression_loss: 0.7\n",
      " — ate_err: 1.9503  — cate_err: 2.5310 — cate_nn_err: 3.0369 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - cfrnet_loss: 0.7977 - loss: 5.4574 - mmdsq_loss: 0.0722 - regression_loss: 0.7255 - val_cfrnet_loss: 1.0875 - val_loss: 5.6221 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.8804 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  cfrnet_loss: 0.6741 - loss: 5.3044 - mmdsq_loss: 0.0741 - regression_loss: 0\n",
      " — ate_err: 1.2340  — cate_err: 2.0859 — cate_nn_err: 2.5176 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - cfrnet_loss: 0.6466 - loss: 5.2728 - mmdsq_loss: 0.0722 - regression_loss: 0.5744 - val_cfrnet_loss: 0.9515 - val_loss: 5.4535 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.7444 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  cfrnet_loss: 0.5519 - loss: 5.1455 - mmdsq_loss: 0.0733 - regression_loss: 0.4\n",
      " — ate_err: 0.7797  — cate_err: 1.9402 — cate_nn_err: 2.2206 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - cfrnet_loss: 0.5427 - loss: 5.1335 - mmdsq_loss: 0.0722 - regression_loss: 0.4704 - val_cfrnet_loss: 0.8366 - val_loss: 5.3084 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.6296 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.4885 - loss: 5.0466 - mmdsq_loss: 0.0741 - regression_loss: 0.414\n",
      " — ate_err: 0.5298  — cate_err: 1.9635 — cate_nn_err: 2.0561 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - cfrnet_loss: 0.4712 - loss: 5.0249 - mmdsq_loss: 0.0722 - regression_loss: 0.3990 - val_cfrnet_loss: 0.7484 - val_loss: 5.1890 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.5413 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.4388 - loss: 4.9582 - mmdsq_loss: 0.0741 - regression_loss: 0.3\n",
      " — ate_err: 0.3751  — cate_err: 2.0471 — cate_nn_err: 1.9525 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - cfrnet_loss: 0.4234 - loss: 4.9383 - mmdsq_loss: 0.0722 - regression_loss: 0.3512 - val_cfrnet_loss: 0.6827 - val_loss: 5.0887 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.4756 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.3939 - loss: 4.8718 - mmdsq_loss: 0.0733 - regression_loss: 0.3\n",
      " — ate_err: 0.2910  — cate_err: 2.1459 — cate_nn_err: 1.8899 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - cfrnet_loss: 0.3876 - loss: 4.8625 - mmdsq_loss: 0.0722 - regression_loss: 0.3154 - val_cfrnet_loss: 0.6354 - val_loss: 5.0031 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.4283 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.3754 - loss: 4.8141 - mmdsq_loss: 0.0741 - regression_loss: 0.3\n",
      " — ate_err: 0.3304  — cate_err: 2.2394 — cate_nn_err: 1.8708 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - cfrnet_loss: 0.3623 - loss: 4.7963 - mmdsq_loss: 0.0722 - regression_loss: 0.2900 - val_cfrnet_loss: 0.6059 - val_loss: 4.9332 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3988 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.3536 - loss: 4.7488 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.4304  — cate_err: 2.3049 — cate_nn_err: 1.8763 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - cfrnet_loss: 0.3470 - loss: 4.7392 - mmdsq_loss: 0.0722 - regression_loss: 0.2748 - val_cfrnet_loss: 0.5901 - val_loss: 4.8756 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3830 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.3441 - loss: 4.6971 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.4593  — cate_err: 2.3175 — cate_nn_err: 1.8619 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - cfrnet_loss: 0.3372 - loss: 4.6871 - mmdsq_loss: 0.0722 - regression_loss: 0.2649 - val_cfrnet_loss: 0.5818 - val_loss: 4.8245 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3747 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.3314 - loss: 4.6401 - mmdsq_loss: 0.0727 - regression_loss: 0.2\n",
      " — ate_err: 0.4316  — cate_err: 2.2938 — cate_nn_err: 1.8291 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - cfrnet_loss: 0.3285 - loss: 4.6359 - mmdsq_loss: 0.0722 - regression_loss: 0.2563 - val_cfrnet_loss: 0.5770 - val_loss: 4.7766 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3699 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.3335 - loss: 4.6033 - mmdsq_loss: 0.0741 - regression_loss: 0.2\n",
      " — ate_err: 0.4129  — cate_err: 2.2681 — cate_nn_err: 1.8029 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - cfrnet_loss: 0.3202 - loss: 4.5853 - mmdsq_loss: 0.0722 - regression_loss: 0.2480 - val_cfrnet_loss: 0.5736 - val_loss: 4.7309 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3666 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.3260 - loss: 4.5536 - mmdsq_loss: 0.0741 - regression_loss: 0.251\n",
      " — ate_err: 0.3882  — cate_err: 2.2481 — cate_nn_err: 1.7799 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - cfrnet_loss: 0.3132 - loss: 4.5361 - mmdsq_loss: 0.0722 - regression_loss: 0.2410 - val_cfrnet_loss: 0.5707 - val_loss: 4.6861 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3636 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.3199 - loss: 4.5057 - mmdsq_loss: 0.0741 - regression_loss: 0.2\n",
      " — ate_err: 0.3540  — cate_err: 2.2361 — cate_nn_err: 1.7586 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - cfrnet_loss: 0.3076 - loss: 4.4886 - mmdsq_loss: 0.0722 - regression_loss: 0.2354 - val_cfrnet_loss: 0.5678 - val_loss: 4.6417 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3607 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.3056 - loss: 4.4463 - mmdsq_loss: 0.0727 - regression_loss: 0.232\n",
      " — ate_err: 0.3404  — cate_err: 2.2362 — cate_nn_err: 1.7468 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - cfrnet_loss: 0.3031 - loss: 4.4425 - mmdsq_loss: 0.0722 - regression_loss: 0.2308 - val_cfrnet_loss: 0.5647 - val_loss: 4.5973 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3576 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.3110 - loss: 4.4139 - mmdsq_loss: 0.0741 - regression_loss: 0.2\n",
      " — ate_err: 0.3391  — cate_err: 2.2422 — cate_nn_err: 1.7409 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - cfrnet_loss: 0.2993 - loss: 4.3975 - mmdsq_loss: 0.0722 - regression_loss: 0.2271 - val_cfrnet_loss: 0.5615 - val_loss: 4.5530 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3545 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  cfrnet_loss: 0.3020 - loss: 4.3620 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.3339  — cate_err: 2.2473 — cate_nn_err: 1.7350 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - cfrnet_loss: 0.2962 - loss: 4.3533 - mmdsq_loss: 0.0722 - regression_loss: 0.2239 - val_cfrnet_loss: 0.5587 - val_loss: 4.5091 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3516 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  cfrnet_loss: 0.2991 - loss: 4.3183 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.3309  — cate_err: 2.2510 — cate_nn_err: 1.7306 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - cfrnet_loss: 0.2934 - loss: 4.3097 - mmdsq_loss: 0.0722 - regression_loss: 0.2212 - val_cfrnet_loss: 0.5561 - val_loss: 4.4657 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3490 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.3018 - loss: 4.2821 - mmdsq_loss: 0.0741 - regression_loss: 0.2\n",
      " — ate_err: 0.3279  — cate_err: 2.2527 — cate_nn_err: 1.7263 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - cfrnet_loss: 0.2910 - loss: 4.2667 - mmdsq_loss: 0.0722 - regression_loss: 0.2187 - val_cfrnet_loss: 0.5536 - val_loss: 4.4228 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3466 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2941 - loss: 4.2324 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.3204  — cate_err: 2.2520 — cate_nn_err: 1.7209 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - cfrnet_loss: 0.2887 - loss: 4.2242 - mmdsq_loss: 0.0722 - regression_loss: 0.2165 - val_cfrnet_loss: 0.5514 - val_loss: 4.3803 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3443 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2919 - loss: 4.1902 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.3138  — cate_err: 2.2512 — cate_nn_err: 1.7160 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - cfrnet_loss: 0.2867 - loss: 4.1822 - mmdsq_loss: 0.0722 - regression_loss: 0.2145 - val_cfrnet_loss: 0.5492 - val_loss: 4.3383 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3421 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2900 - loss: 4.1485 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.3089  — cate_err: 2.2508 — cate_nn_err: 1.7118 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - cfrnet_loss: 0.2849 - loss: 4.1407 - mmdsq_loss: 0.0722 - regression_loss: 0.2127 - val_cfrnet_loss: 0.5470 - val_loss: 4.2966 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3399 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2931 - loss: 4.1138 - mmdsq_loss: 0.0741 - regression_loss: 0.2\n",
      " — ate_err: 0.3041  — cate_err: 2.2509 — cate_nn_err: 1.7077 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - cfrnet_loss: 0.2832 - loss: 4.0996 - mmdsq_loss: 0.0722 - regression_loss: 0.2110 - val_cfrnet_loss: 0.5450 - val_loss: 4.2553 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3379 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2866 - loss: 4.0666 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.3008  — cate_err: 2.2515 — cate_nn_err: 1.7042 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - cfrnet_loss: 0.2817 - loss: 4.0590 - mmdsq_loss: 0.0722 - regression_loss: 0.2095 - val_cfrnet_loss: 0.5430 - val_loss: 4.2143 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3359 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2851 - loss: 4.0263 - mmdsq_loss: 0.0733 - regression_loss: 0.211\n",
      " — ate_err: 0.2983  — cate_err: 2.2523 — cate_nn_err: 1.7010 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - cfrnet_loss: 0.2803 - loss: 4.0187 - mmdsq_loss: 0.0722 - regression_loss: 0.2081 - val_cfrnet_loss: 0.5410 - val_loss: 4.1738 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3339 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2883 - loss: 3.9926 - mmdsq_loss: 0.0741 - regression_loss: 0.2\n",
      " — ate_err: 0.2955  — cate_err: 2.2530 — cate_nn_err: 1.6977 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - cfrnet_loss: 0.2790 - loss: 3.9789 - mmdsq_loss: 0.0722 - regression_loss: 0.2067 - val_cfrnet_loss: 0.5391 - val_loss: 4.1336 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3321 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2823 - loss: 3.9468 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.2930  — cate_err: 2.2535 — cate_nn_err: 1.6945 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - cfrnet_loss: 0.2777 - loss: 3.9395 - mmdsq_loss: 0.0722 - regression_loss: 0.2055 - val_cfrnet_loss: 0.5373 - val_loss: 4.0938 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3302 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2810 - loss: 3.9077 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.2908  — cate_err: 2.2539 — cate_nn_err: 1.6914 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - cfrnet_loss: 0.2765 - loss: 3.9005 - mmdsq_loss: 0.0722 - regression_loss: 0.2043 - val_cfrnet_loss: 0.5355 - val_loss: 4.0544 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3284 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2798 - loss: 3.8689 - mmdsq_loss: 0.0733 - regression_loss: 0.206\n",
      " — ate_err: 0.2886  — cate_err: 2.2542 — cate_nn_err: 1.6884 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - cfrnet_loss: 0.2753 - loss: 3.8618 - mmdsq_loss: 0.0722 - regression_loss: 0.2031 - val_cfrnet_loss: 0.5337 - val_loss: 4.0153 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3267 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2786 - loss: 3.8305 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.2870  — cate_err: 2.2545 — cate_nn_err: 1.6855 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - cfrnet_loss: 0.2742 - loss: 3.8234 - mmdsq_loss: 0.0722 - regression_loss: 0.2020 - val_cfrnet_loss: 0.5320 - val_loss: 3.9766 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3249 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2750 - loss: 3.7884 - mmdsq_loss: 0.0727 - regression_loss: 0.202\n",
      " — ate_err: 0.2855  — cate_err: 2.2550 — cate_nn_err: 1.6827 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - cfrnet_loss: 0.2731 - loss: 3.7855 - mmdsq_loss: 0.0722 - regression_loss: 0.2009 - val_cfrnet_loss: 0.5303 - val_loss: 3.9383 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3232 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2739 - loss: 3.7507 - mmdsq_loss: 0.0727 - regression_loss: 0.201\n",
      " — ate_err: 0.2843  — cate_err: 2.2555 — cate_nn_err: 1.6801 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - cfrnet_loss: 0.2721 - loss: 3.7478 - mmdsq_loss: 0.0722 - regression_loss: 0.1999 - val_cfrnet_loss: 0.5286 - val_loss: 3.9002 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3215 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2729 - loss: 3.7134 - mmdsq_loss: 0.0727 - regression_loss: 0.200\n",
      " — ate_err: 0.2832  — cate_err: 2.2560 — cate_nn_err: 1.6775 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - cfrnet_loss: 0.2711 - loss: 3.7105 - mmdsq_loss: 0.0722 - regression_loss: 0.1989 - val_cfrnet_loss: 0.5269 - val_loss: 3.8626 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3198 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2719 - loss: 3.6764 - mmdsq_loss: 0.0727 - regression_loss: 0.199\n",
      " — ate_err: 0.2822  — cate_err: 2.2566 — cate_nn_err: 1.6750 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - cfrnet_loss: 0.2701 - loss: 3.6736 - mmdsq_loss: 0.0722 - regression_loss: 0.1979 - val_cfrnet_loss: 0.5253 - val_loss: 3.8253 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3182 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2734 - loss: 3.6437 - mmdsq_loss: 0.0733 - regression_loss: 0.2\n",
      " — ate_err: 0.2812  — cate_err: 2.2572 — cate_nn_err: 1.6726 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - cfrnet_loss: 0.2692 - loss: 3.6370 - mmdsq_loss: 0.0722 - regression_loss: 0.1970 - val_cfrnet_loss: 0.5237 - val_loss: 3.7883 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3166 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2724 - loss: 3.6074 - mmdsq_loss: 0.0733 - regression_loss: 0.199\n",
      " — ate_err: 0.2804  — cate_err: 2.2579 — cate_nn_err: 1.6703 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - cfrnet_loss: 0.2683 - loss: 3.6008 - mmdsq_loss: 0.0722 - regression_loss: 0.1961 - val_cfrnet_loss: 0.5221 - val_loss: 3.7517 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3150 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2691 - loss: 3.5676 - mmdsq_loss: 0.0727 - regression_loss: 0.196\n",
      " — ate_err: 0.2796  — cate_err: 2.2586 — cate_nn_err: 1.6680 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - cfrnet_loss: 0.2674 - loss: 3.5649 - mmdsq_loss: 0.0722 - regression_loss: 0.1952 - val_cfrnet_loss: 0.5205 - val_loss: 3.7154 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3134 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2682 - loss: 3.5320 - mmdsq_loss: 0.0727 - regression_loss: 0.195\n",
      " — ate_err: 0.2789  — cate_err: 2.2593 — cate_nn_err: 1.6658 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - cfrnet_loss: 0.2665 - loss: 3.5293 - mmdsq_loss: 0.0722 - regression_loss: 0.1943 - val_cfrnet_loss: 0.5190 - val_loss: 3.6795 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3119 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2740 - loss: 3.5062 - mmdsq_loss: 0.0741 - regression_loss: 0.1\n",
      " — ate_err: 0.2783  — cate_err: 2.2601 — cate_nn_err: 1.6637 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - cfrnet_loss: 0.2657 - loss: 3.4941 - mmdsq_loss: 0.0722 - regression_loss: 0.1935 - val_cfrnet_loss: 0.5175 - val_loss: 3.6439 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3104 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2731 - loss: 3.4712 - mmdsq_loss: 0.0741 - regression_loss: 0.1\n",
      " — ate_err: 0.2778  — cate_err: 2.2608 — cate_nn_err: 1.6617 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - cfrnet_loss: 0.2649 - loss: 3.4592 - mmdsq_loss: 0.0722 - regression_loss: 0.1927 - val_cfrnet_loss: 0.5160 - val_loss: 3.6087 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3089 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2680 - loss: 3.4309 - mmdsq_loss: 0.0733 - regression_loss: 0.1\n",
      " — ate_err: 0.2773  — cate_err: 2.2616 — cate_nn_err: 1.6598 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - cfrnet_loss: 0.2641 - loss: 3.4246 - mmdsq_loss: 0.0722 - regression_loss: 0.1919 - val_cfrnet_loss: 0.5146 - val_loss: 3.5738 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3075 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  cfrnet_loss: 0.2715 - loss: 3.4022 - mmdsq_loss: 0.0741 - regression_loss: 0.1\n",
      " — ate_err: 0.2768  — cate_err: 2.2625 — cate_nn_err: 1.6579 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - cfrnet_loss: 0.2633 - loss: 3.3904 - mmdsq_loss: 0.0722 - regression_loss: 0.1911 - val_cfrnet_loss: 0.5132 - val_loss: 3.5392 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3061 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2665 - loss: 3.3627 - mmdsq_loss: 0.0733 - regression_loss: 0.1\n",
      " — ate_err: 0.2764  — cate_err: 2.2633 — cate_nn_err: 1.6561 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - cfrnet_loss: 0.2626 - loss: 3.3564 - mmdsq_loss: 0.0722 - regression_loss: 0.1904 - val_cfrnet_loss: 0.5118 - val_loss: 3.5050 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3047 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2657 - loss: 3.3290 - mmdsq_loss: 0.0733 - regression_loss: 0.1\n",
      " — ate_err: 0.2760  — cate_err: 2.2641 — cate_nn_err: 1.6544 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - cfrnet_loss: 0.2619 - loss: 3.3229 - mmdsq_loss: 0.0722 - regression_loss: 0.1897 - val_cfrnet_loss: 0.5105 - val_loss: 3.4711 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3034 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2650 - loss: 3.2957 - mmdsq_loss: 0.0733 - regression_loss: 0.191\n",
      " — ate_err: 0.2757  — cate_err: 2.2649 — cate_nn_err: 1.6528 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - cfrnet_loss: 0.2612 - loss: 3.2896 - mmdsq_loss: 0.0722 - regression_loss: 0.1890 - val_cfrnet_loss: 0.5092 - val_loss: 3.4375 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3021 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2621 - loss: 3.2592 - mmdsq_loss: 0.0727 - regression_loss: 0.189\n",
      " — ate_err: 0.2754  — cate_err: 2.2657 — cate_nn_err: 1.6512 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - cfrnet_loss: 0.2605 - loss: 3.2566 - mmdsq_loss: 0.0722 - regression_loss: 0.1883 - val_cfrnet_loss: 0.5079 - val_loss: 3.4043 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.3008 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2636 - loss: 3.2300 - mmdsq_loss: 0.0733 - regression_loss: 0.190\n",
      " — ate_err: 0.2751  — cate_err: 2.2666 — cate_nn_err: 1.6497 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - cfrnet_loss: 0.2599 - loss: 3.2240 - mmdsq_loss: 0.0722 - regression_loss: 0.1877 - val_cfrnet_loss: 0.5067 - val_loss: 3.3714 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.2996 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2629 - loss: 3.1977 - mmdsq_loss: 0.0733 - regression_loss: 0.1\n",
      " — ate_err: 0.2749  — cate_err: 2.2674 — cate_nn_err: 1.6482 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - cfrnet_loss: 0.2592 - loss: 3.1917 - mmdsq_loss: 0.0722 - regression_loss: 0.1870 - val_cfrnet_loss: 0.5055 - val_loss: 3.3388 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.2984 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2602 - loss: 3.1622 - mmdsq_loss: 0.0727 - regression_loss: 0.187\n",
      " — ate_err: 0.2746  — cate_err: 2.2682 — cate_nn_err: 1.6468 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - cfrnet_loss: 0.2586 - loss: 3.1597 - mmdsq_loss: 0.0722 - regression_loss: 0.1864 - val_cfrnet_loss: 0.5043 - val_loss: 3.3066 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.2972 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  cfrnet_loss: 0.2617 - loss: 3.1339 - mmdsq_loss: 0.0733 - regression_loss: 0.188\n",
      " — ate_err: 0.2744  — cate_err: 2.2690 — cate_nn_err: 1.6454 — true_ate: 3.8537\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - cfrnet_loss: 0.2580 - loss: 3.1280 - mmdsq_loss: 0.0722 - regression_loss: 0.1858 - val_cfrnet_loss: 0.5032 - val_loss: 3.2747 - val_mmdsq_loss: 0.2071 - val_regression_loss: 0.2961 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f8bddc63610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, TerminateOnNaN\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "#Colab command to allow us to run Colab in TF2\n",
    "%load_ext tensorboard \n",
    "\n",
    "val_split=0.2\n",
    "batch_size=100\n",
    "verbose=1\n",
    "i = 0\n",
    "tf.random.set_seed(i)\n",
    "np.random.seed(i)\n",
    "yt = np.concatenate([data['ys'], data['t']], 1)\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "\n",
    "#let's try ADAM this time\n",
    "adam_callbacks = [\n",
    "        TerminateOnNaN(),\n",
    "        EarlyStopping(monitor='val_loss', patience=2, min_delta=0.),\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n",
    "                          min_delta=1e-8, cooldown=0, min_lr=0),\n",
    "        tensorboard_callback,\n",
    "        Base_Metrics(data,verbose=verbose)\n",
    "    ]\n",
    "\n",
    "\n",
    "cfrnet_model=make_tarnet(25,.01)\n",
    "cfrnet_loss=CFRNet_Loss(alpha=1.0)\n",
    "\n",
    "cfrnet_model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                      loss=cfrnet_loss,\n",
    "                 metrics=[cfrnet_loss,cfrnet_loss.regression_loss,cfrnet_loss.mmdsq_loss])\n",
    "\n",
    "cfrnet_model.fit(x=data['x'],y=yt,\n",
    "                 callbacks=adam_callbacks,\n",
    "                  validation_split=val_split,\n",
    "                  epochs=50,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b3771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5274), started 1 day, 20:33:31 ago. (Use '!kill 5274' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c6493e7637cabd52\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c6493e7637cabd52\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Output shape: (1, 2)\n",
      "Output values: [[0.12490655 1.3903079 ]]\n",
      "Predicted y0: 0.12490654736757278\n",
      "Predicted y1: 1.390307903289795\n"
     ]
    }
   ],
   "source": [
    "input_dim=data['x'].shape[1]\n",
    "x_test = np.random.rand(1, input_dim).astype(np.float32)\n",
    "\n",
    "output = cfrnet_model.predict(x_test)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output)\n",
    "\n",
    "y0_pred = output[0, 0]\n",
    "y1_pred = output[0, 1]\n",
    "\n",
    "print(f\"Predicted y0: {y0_pred}\")\n",
    "print(f\"Predicted y1: {y1_pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
